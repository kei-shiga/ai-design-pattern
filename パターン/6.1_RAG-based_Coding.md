# 6.1 RAG-based Coding (Retrieval-Augmented Generation)

## 概要
LLMのコンテキストウィンドウには限りがあるため、大規模なコードベース全体を一度に入力することはできません。
**RAG (Retrieval-Augmented Generation)** を用いて、プロジェクトのコードやドキュメントをベクトル化して保存し、ユーザーの質問に関連するファイルや関数だけを動的に検索・注入することで、リポジトリ全体を理解しているかのように振る舞わせる手法です。

## 詳細・実施手順

1. **Indexing (インデックス作成):**
   * リポジトリ内の全ファイル（`.py`, `.ts`, `.md`等）をスキャンします。
   * ファイルを適切なサイズ（Chunk）に分割します。関数単位やクラス単位での分割が効果的です。
   * 各ChunkをEmbeddingモデル（OpenAI text-embedding-3-small等）でベクトル化し、Vector DB（Chroma, Pinecone, pgvector等）に保存します。

2. **Retrieval (検索):**
   * ユーザーの質問（Query）を同じモデルでベクトル化します。
   * Vector DBから、Queryと意味的（Semantic）に近いChunkを上位N件取得します。
   * キーワード検索（BM25）を併用する「ハイブリッド検索」も有効です。

3. **Generation (生成):**
   * 検索で得られたChunkを「参考コンテキスト」としてプロンプトに結合し、LLMに回答を生成させます。

## プロンプト構成イメージ

```markdown
# Context
以下のプロジェクトコード断片を参考にしてください。

[File: src/auth/login.py]
def login(user, pass): ...

[File: src/models/user.py]
class User: ...

# Question
ユーザーログイン時に `last_login_at` を更新するロジックを追加したいです。
どのファイルをどのように修正すべきですか？
```

## ツール・ライブラリの活用

自前で実装するのは大変なため、既存ツールを活用するのが一般的です。

* **Cursor / Copilot:** IDE標準でこのRAG機能（Codebase Search）を持っています（`@Codebase` 等）。
* **LlamaIndex / LangChain:** RAGパイプラインを構築するためのライブラリ。
* **Greptile / Bloop:** コードベース検索に特化したSaaS。

## メリット
- **スケーラビリティ:** どんなに巨大なリポジトリでも、検索精度さえ良ければAIが扱えます。
- **ハルシネーション低減:** 「憶測」ではなく「実際に存在するコード」を元に回答するため、嘘が減ります。
- **ドキュメント活用:** 仕様書や設計書も検索対象にすれば、仕様に準拠した実装が可能になります。
